{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision.models import vgg19, VGG19_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_img = Image.open(\"./notebook_images/starry_night.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 128\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_tensor = transform(style_img)\n",
    "style_tensor = style_tensor.unsqueeze(0)\n",
    "print(f\"style_tensor shape: {style_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_tensor = torch.randn(1, 3, 128, 128)\n",
    "print(f\"noise_tneosr shape: {noise_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_model = vgg19(weights=VGG19_Weights.DEFAULT).features.eval()\n",
    "\n",
    "model = nn.Sequential()\n",
    "i = 0\n",
    "for layer in vgg19_model.children():\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        i += 1\n",
    "        name = f'conv_{i}'\n",
    "    elif isinstance(layer, nn.ReLU):\n",
    "        name = f'relu_{i}'\n",
    "        layer = nn.ReLU(inplace=False)\n",
    "    elif isinstance(layer, nn.MaxPool2d):\n",
    "        layer = nn.AvgPool2d(2, 2)\n",
    "        name = f'pool_{i}'\n",
    "    elif isinstance(layer, nn.BatchNorm2d):\n",
    "        name = f'bn_{i}'\n",
    "    \n",
    "    model.add_module(name, layer)\n",
    "\n",
    "    if name == f'conv_5':\n",
    "        break\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(input):\n",
    "    a, b, c, d = input.size()  # a=배치 크기(=1)\n",
    "    # b=특징 맵의 수\n",
    "    # (c,d)=특징 맵의 차원 (N=c*d)\n",
    "\n",
    "    features = input.view(a * b, c * d)  # F_XL을 \\hat F_XL로 크기 조정\n",
    "\n",
    "    G = torch.mm(features, features.t())  # gram product를 계산\n",
    "\n",
    "    # 각 특징 맵이 갖는 값의 수로 나누어\n",
    "    # gram 행렬의 값을 '정규화'\n",
    "    return G.div(a * b * c * d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = model.to(device)\n",
    "style_tensor_output = style_tensor.clone().to(device)\n",
    "\n",
    "style_tensor_results = {}\n",
    "for name, layer in model.named_children():\n",
    "    style_tensor_output = layer(style_tensor_output)\n",
    "    style_tensor_results[name] = style_tensor_output\n",
    "\n",
    "required_tensor = torch.nn.Parameter(noise_tensor.clone().to(device))\n",
    "optimizer = optim.SGD([required_tensor])\n",
    "\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output_tensor = required_tensor\n",
    "    with torch.no_grad():\n",
    "        output_tensor.clamp_(0, 1) # replace\n",
    "\n",
    "    loss = 0.0\n",
    "    for name, layer in model.named_children():\n",
    "        output_tensor = layer(output_tensor)\n",
    "\n",
    "        if name == \"conv_1\":\n",
    "            style_G = gram_matrix(style_tensor_results[\"conv_1\"].detach())\n",
    "            noise_G = gram_matrix(output_tensor)\n",
    "            loss += F.mse_loss(noise_G, style_G)\n",
    "        elif name == \"conv_2\":\n",
    "            style_G = gram_matrix(style_tensor_results[\"conv_2\"].detach())\n",
    "            noise_G = gram_matrix(output_tensor)\n",
    "            loss += F.mse_loss(noise_G, style_G)\n",
    "        elif name == \"conv_3\":\n",
    "            style_G = gram_matrix(style_tensor_results[\"conv_3\"].detach())\n",
    "            noise_G = gram_matrix(output_tensor)\n",
    "            loss += F.mse_loss(noise_G, style_G)\n",
    "        elif name == \"conv_4\":\n",
    "            style_G = gram_matrix(style_tensor_results[\"conv_4\"].detach())\n",
    "            noise_G = gram_matrix(output_tensor)\n",
    "            loss += F.mse_loss(noise_G, style_G)\n",
    "        elif name == \"conv_5\":\n",
    "            style_G = gram_matrix(style_tensor_results[\"conv_5\"].detach())\n",
    "            noise_G = gram_matrix(output_tensor)\n",
    "            loss += F.mse_loss(noise_G, style_G)\n",
    "        \n",
    "        loss *= 1000\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"{epoch}/{epochs} loss: {loss.item():.4f}\")\n",
    "\n",
    "    if loss == 0.0:\n",
    "        print(f\"Train finished\")\n",
    "        break\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_tensor.clamp_(0, 1) # replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
